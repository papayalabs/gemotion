<div class="flex flex-col items-center mb-45">
  <h1 class="video-h1 pb-40">Ajoutez votre partie vidéo à  la dédicace finale</h1>
  <%= render "shared/profile_tabs", page_count: 1 %>
</div>

<!-- Add TensorFlow.js and BodyPix dependencies -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.2.0"></script>

<div class=''>
  <%= form_with url: creator_dedicace_de_fin_post_path(video_id: @video.id), method: :post, multipart: true, html: {data: { turbo: false }} do |f| %>
  <div class="frame-no-border">
    <div class="dedications">
      <% @dedicaces.each do |dedicace| %>
      <div class="dedication">
        <%= f.radio_button "video_dedicace", dedicace.id, {checked: dedicace == @video_dedicace&.dedicace}%>
        <div class="dedication-wrapper">
          <div class="dedication-thumb-wrapper">
            <% if dedicace.video.attached? %>
            <div class="video-wrapper">
              <%= video_tag dedicace.video, controls: false, class: "video-content h-[150px] w-[150px] br-10" %>
              <div class="play-icon">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none">
                  <defs>
                    <linearGradient id="play-icon-gradient" x1="0%" y1="100%" x2="0%" y2="0%">
                      <stop offset="0%" stop-color="#163F50" />
                      <stop offset="50%" stop-color="#0D6783" />
                      <stop offset="100%" stop-color="#C9E1FF" />
                    </linearGradient>
                  </defs>
                  <path d="M8 5v14l11-7z" fill="url(#play-icon-gradient)" />
                </svg>
              </div>
            </div>
            <% else %>
            <p>Pas de vidéo</p>
            <% end %>
            <span class="dedication-name"><%= dedicace.name %></span>
          </div>
          <p class="p-text-16 mt-4"><%= dedicace.description %></p>
          <p class="p-text-16-bold mt-2 text-decoration-underline">Lire plus</p>
        </div>
      </div>
      <% end %>
    </div>
  </div>

  <div class="flex flex-col justify-start items-center mt-65">
    <div class="dedicace-de-fin-frame mt-6 flex flex-col justify-start items-start">
      <div class="flex justify-start items-center">
        <div class="mr-2 p-text-16">Vos médias</div>
        <div class="flex justify-start items-center p-text-16">
          <%= image_tag 'icons/mingcute_time-line.png', alt: 'Time Icon', class: 'inline-block ml-15 mr-2', style: 'height: 24px; width: 24px;' %>
          <% if @video_dedicace.present? && @video_dedicace.creator_end_dedication_video.attached? %>
          <%= @video_dedicace.video_duration%>
          <% else %>
          Duration: N/A
          <% end %>
        </div>
      </div>

      <div class="flex justify-start items-center mt-2">
        <div class="mr-2 font-bold p-text-bold-16">Thème:</div>
        <div class="flex justify-start items-center p-text-16">
          <%=@dedicace.name%>
        </div>
      </div>
      <div class="w-full flex justify-center items-center">
        <div class="video-slots-container relative">
          <!-- Background image container -->
          <div id="backgroundContainer" class="absolute inset-0">
            <img src="/assets/dedicace-carpool-background.jpg" class="w-full h-full object-cover" id="carBackground">
          </div>

          <!-- Video slots -->
          <div class="video-slots absolute inset-0 flex justify-around items-center">
            <% (1..3).each do |slot_number| %>
              <div class="video-slot" data-slot-number="<%= slot_number %>">
                <% if @video_dedicace.has_video_in_slot?(slot_number) %>
                  <img src="<%= @video_dedicace.get_video_preview(slot_number) %>" class="video-preview" alt="Video Preview">
                  <div class="re-record-overlay">
                    <span>Re-record?</span>
                  </div>
                <% else %>
                  <div class="plus-button">+</div>
                <% end %>
              </div>
            <% end %>
          </div>
        </div>
      </div>

      <!-- Recording Modal -->
      <div id="recordingModal" class="modal" style="display: none;">
        <div class="modal-content">
          <div class="video-recording-block flex justify-center items-center relative">
            <video id="videoPreview" class="absolute inset-0 w-full h-full object-cover" style="display: none;" playsinline muted></video>
            <canvas id="outputCanvas" class="absolute inset-0 w-full h-full"></canvas>
            
            <div id="recordingTimer" class="absolute top-4 right-4 bg-red-500 text-white px-3 py-1 rounded" style="display: none;">
              30s
            </div>
          </div>

          <div class="modal-buttons">
            <button type="button" id="startRecording" class="record-transparent">
              <%= image_tag "icons/fluent_record-24-regular.png", alt: "Start Recording", class: "inline-block", style: "height: 16px; width: 16px;" %>
              Commencer l'enregistrement vidéo
            </button>

            <button type="button" id="stopRecording" class="record-transparent" style="display: none;">
              <%= image_tag "icons/fluent_record-24-regular.png", alt: "Stop Recording", class: "inline-block", style: "height: 16px; width: 16px;" %>
              Arrêter l'enregistrement vidéo
            </button>

            <button type="button" id="confirmRecording" class="black-link" style="display: none;">
              OK
            </button>

            <button type="button" id="cancelRecording" class="black-link">
              Annuler
            </button>
          </div>
        </div>
      </div>
    </div>
    <%= f.submit "Sauvegarder les modification", class: "black-link mt-6" %>
  </div>
  <% end %>
</div>

<style>
  .video-slots-container {
    aspect-ratio: 16/9;
    background: #f5f5f5;
    border-radius: 15px;
    overflow: hidden;
    position: relative;
    width: 100%;
    max-width: 800px;
  }

  .video-slots {
    padding: 20px;
  }

  .video-slot {
    width: 120px;
    height: 120px;
    border-radius: 50%;
    background: rgba(255, 255, 255, 0.8);
    display: flex;
    justify-content: center;
    align-items: center;
    cursor: pointer;
    position: relative;
    overflow: hidden;
  }

  .video-slot:hover .re-record-overlay {
    opacity: 1;
  }

  .re-record-overlay {
    position: absolute;
    inset: 0;
    background: rgba(0, 0, 0, 0.5);
    display: flex;
    justify-content: center;
    align-items: center;
    color: white;
    opacity: 0;
    transition: opacity 0.3s ease;
  }

  .plus-button {
    font-size: 48px;
    color: #000;
  }

  .modal {
    position: fixed;
    inset: 0;
    background: rgba(0, 0, 0, 0.5);
    display: flex;
    justify-content: center;
    align-items: center;
    z-index: 1000;
  }

  .modal-content {
    background: white;
    padding: 20px;
    border-radius: 15px;
    width: 90%;
    max-width: 800px;
  }

  .modal-buttons {
    display: flex;
    justify-content: center;
    gap: 20px;
    margin-top: 20px;
  }

  .video-preview {
    width: 100%;
    height: 100%;
    object-fit: cover;
  }

  .video-recording-block {
    aspect-ratio: 16/9;
    background: #f5f5f5;
    border-radius: 15px;
    overflow: hidden;
    position: relative;
  }
</style>

<script>
document.addEventListener("DOMContentLoaded", () => {
  let bodyPixNet;
  let mediaRecorder;
  let recordedChunks = [];
  let recordingInterval;
  let timeLeft = 30;
  let isRecording = false;
  let currentSlot = null;
  let firstFrameData = null;

  const videoPreview = document.getElementById("videoPreview");
  const outputCanvas = document.getElementById("outputCanvas");
  const recordingTimer = document.getElementById("recordingTimer");
  const startButton = document.getElementById("startRecording");
  const stopButton = document.getElementById("stopRecording");
  const confirmButton = document.getElementById("confirmRecording");
  const cancelButton = document.getElementById("cancelRecording");
  const recordingModal = document.getElementById("recordingModal");
  const videoSlots = document.querySelectorAll(".video-slot");

  // Initialize BodyPix
  async function initBodyPix() {
    try {
      bodyPixNet = await bodyPix.load({
        architecture: 'MobileNetV1',
        outputStride: 16,
        multiplier: 0.5,
        quantBytes: 2
      });
      console.log('BodyPix model loaded successfully');
      return true;
    } catch (error) {
      console.error('Error loading BodyPix:', error);
      alert('Failed to initialize video processing. Please refresh the page and try again.');
      return false;
    }
  }

  // Process video frame
  async function processFrame() {
    if (!isRecording || !videoPreview.videoWidth) return;

    try {
      if (outputCanvas.width !== videoPreview.videoWidth || outputCanvas.height !== videoPreview.videoHeight) {
        outputCanvas.width = videoPreview.videoWidth;
        outputCanvas.height = videoPreview.videoHeight;
      }

      const ctx = outputCanvas.getContext('2d');
      const segmentation = await bodyPixNet.segmentPerson(videoPreview, {
        flipHorizontal: false,
        internalResolution: 'medium',
        segmentationThreshold: 0.5
      });

      // Draw original video frame first
      ctx.drawImage(videoPreview, 0, 0);

      // Create a temporary canvas for the mask
      const maskCanvas = document.createElement('canvas');
      maskCanvas.width = outputCanvas.width;
      maskCanvas.height = outputCanvas.height;
      const maskCtx = maskCanvas.getContext('2d');

      // Create the mask
      const imageData = maskCtx.createImageData(maskCanvas.width, maskCanvas.height);
      const data = imageData.data;
      for (let i = 0; i < segmentation.data.length; i++) {
        const pixelIndex = i * 4;
        if (segmentation.data[i] === 0) { // If it's background
          data[pixelIndex + 3] = 0; // Set alpha to 0
        }
      }
      maskCtx.putImageData(imageData, 0, 0);

      // Apply the mask to the original frame
      ctx.globalCompositeOperation = 'destination-in';
      ctx.drawImage(maskCanvas, 0, 0);
      ctx.globalCompositeOperation = 'source-over';

      if (isRecording) {
        requestAnimationFrame(processFrame);
      }
    } catch (error) {
      console.error('Error processing frame:', error);
      if (isRecording) {
        requestAnimationFrame(processFrame);
      }
    }
  }

  // Open recording modal
  function openRecordingModal(slotNumber) {
    currentSlot = slotNumber;
    recordingModal.style.display = 'flex';
    startButton.style.display = 'block';
    stopButton.style.display = 'none';
    confirmButton.style.display = 'none';
    recordingTimer.style.display = 'none';
  }

  // Close recording modal
  function closeRecordingModal() {
    recordingModal.style.display = 'none';
    if (videoPreview.srcObject) {
      videoPreview.srcObject.getTracks().forEach(track => track.stop());
    }
    currentSlot = null;
    firstFrameData = null;
  }

  // Start recording
  async function startRecording() {
    try {
      isRecording = true;
      recordedChunks = [];
      timeLeft = 30;

      const modelLoaded = await initBodyPix();
      if (!modelLoaded) throw new Error('Failed to load BodyPix model');

      const stream = await navigator.mediaDevices.getUserMedia({
        video: {
          width: { ideal: 1280 },
          height: { ideal: 720 },
          frameRate: { ideal: 30 }
        },
        audio: true
      });

      videoPreview.srcObject = stream;
      videoPreview.muted = true;
      await videoPreview.play();

      // Initialize canvas with correct dimensions
      outputCanvas.width = videoPreview.videoWidth || 1280;
      outputCanvas.height = videoPreview.videoHeight || 720;

      processFrame();

      const canvasStream = outputCanvas.captureStream(30);
      const audioTrack = stream.getAudioTracks()[0];
      const recordStream = new MediaStream([...canvasStream.getTracks(), audioTrack]);

      mediaRecorder = new MediaRecorder(recordStream, {
        mimeType: 'video/webm;codecs=vp8,opus',
        videoBitsPerSecond: 2500000
      });

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          recordedChunks.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        // Ensure we capture a proper frame for preview
        await processFrame(); // Process one more frame
        firstFrameData = outputCanvas.toDataURL('image/png');
      };

      mediaRecorder.start(1000);

      startButton.style.display = 'none';
      stopButton.style.display = 'block';
      recordingTimer.style.display = 'block';

      recordingInterval = setInterval(() => {
        timeLeft--;
        recordingTimer.textContent = `${timeLeft}s`;
        if (timeLeft <= 0) {
          stopRecording();
        }
      }, 1000);

    } catch (err) {
      console.error('Error in recording process:', err);
      alert('Camera access and BodyPix support are required.');
      closeRecordingModal();
    }
  }

  // Stop recording
  function stopRecording() {
    isRecording = false;
    
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      mediaRecorder.stop();
    }

    if (recordingInterval) {
      clearInterval(recordingInterval);
    }

    if (videoPreview.srcObject) {
      videoPreview.srcObject.getTracks().forEach(track => track.stop());
    }

    recordingTimer.style.display = 'none';
    stopButton.style.display = 'none';
    confirmButton.style.display = 'block';

    // Show the last frame in the preview
    const blob = new Blob(recordedChunks, { type: 'video/webm' });
    const videoURL = URL.createObjectURL(blob);
    videoPreview.src = videoURL;
    videoPreview.style.display = 'block';
    videoPreview.play();
  }

  // Confirm recording
  async function confirmRecording() {
    if (!recordedChunks.length) return;

    const formData = new FormData();
    const blob = new Blob(recordedChunks, { type: 'video/webm' });
    formData.append('video_file', blob, 'recorded_video.webm');
    
    // Take a snapshot of the current video frame for preview
    outputCanvas.width = videoPreview.videoWidth;
    outputCanvas.height = videoPreview.videoHeight;
    const ctx = outputCanvas.getContext('2d');
    ctx.drawImage(videoPreview, 0, 0);
    const previewData = outputCanvas.toDataURL('image/png');
    
    formData.append('preview_data', previewData);
    formData.append('slot_number', currentSlot);
    
    // Add CSRF token
    const token = document.querySelector('meta[name="csrf-token"]').getAttribute('content');

    try {
      const url = `http://localhost:5000/videos/${<%= @video.id %>}/update_video_slot`; 
      const response = await fetch(url, {
        method: 'PATCH',
        headers: {
          'X-CSRF-Token': token
        },
        body: formData,
        credentials: 'same-origin'
      });

      if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
      }

      const data = await response.json();
      if (data.success) {
        const slot = document.querySelector(`.video-slot[data-slot-number="${currentSlot}"]`);
        slot.innerHTML = `
          <img src="${data.preview}" class="video-preview" alt="Video Preview">
          <div class="re-record-overlay">
            <span>Re-record?</span>
          </div>
        `;
      } else {
        alert('Failed to save video: ' + (data.errors ? data.errors.join(', ') : 'Unknown error'));
      }
    } catch (error) {
      console.error('Error saving video:', error);
      alert('Failed to save video. Please try again.');
    }

    closeRecordingModal();
  }

  // Event listeners
  videoSlots.forEach(slot => {
    slot.addEventListener('click', () => {
      const slotNumber = slot.dataset.slotNumber;
      const hasVideo = slot.querySelector('.video-preview');
      
      if (hasVideo) {
        if (confirm('Replace existing video?')) {
          openRecordingModal(slotNumber);
        }
      } else {
        openRecordingModal(slotNumber);
      }
    });
  });

  startButton.addEventListener('click', startRecording);
  stopButton.addEventListener('click', stopRecording);
  confirmButton.addEventListener('click', confirmRecording);
  cancelButton.addEventListener('click', closeRecordingModal);

  // Clean up on page unload
  window.addEventListener('beforeunload', () => {
    if (isRecording) {
      stopRecording();
    }
  });
});
</script>